{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import e3x\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "# Disable future warnings.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment of inertia tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moment_of_inertia_tensor(masses, positions):\n",
    "  diag = jnp.sum(positions**2, axis=-1)[..., None, None]*jnp.eye(3)\n",
    "  outer = positions[..., None, :] * positions[..., :, None]\n",
    "  return jnp.sum(masses[..., None, None] * (diag - outer), axis=-3)\n",
    "\n",
    "def generate_datasets(key, num_train=1000, num_valid=100, num_points=10, min_mass=0.0, max_mass=1.0, stdev=1.0):\n",
    "  # Generate random keys.\n",
    "  train_position_key, train_masses_key, valid_position_key, valid_masses_key = jax.random.split(key, num=4)\n",
    "\n",
    "  # Draw random point masses with random positions.\n",
    "  train_positions = stdev * jax.random.normal(train_position_key,  shape=(num_train, num_points, 3))\n",
    "  train_masses = jax.random.uniform(train_masses_key, shape=(num_train, num_points), minval=min_mass, maxval=max_mass)\n",
    "  valid_positions = stdev * jax.random.normal(valid_position_key,  shape=(num_valid, num_points, 3))\n",
    "  valid_masses = jax.random.uniform(valid_masses_key, shape=(num_valid, num_points), minval=min_mass, maxval=max_mass)\n",
    "\n",
    "  # Calculate moment of inertia tensors.\n",
    "  train_inertia_tensor = calculate_moment_of_inertia_tensor(train_masses, train_positions)\n",
    "  valid_inertia_tensor = calculate_moment_of_inertia_tensor(valid_masses, valid_positions)\n",
    "\n",
    "  # Return final train and validation datasets.\n",
    "  train_data = dict(positions=train_positions, masses=train_masses, inertia_tensor=train_inertia_tensor)\n",
    "  valid_data = dict(positions=valid_positions, masses=valid_masses, inertia_tensor=valid_inertia_tensor)\n",
    "  return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  features = 8\n",
    "  max_degree = 1\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, masses, positions):  # Shapes (..., N) and (..., N, 3).\n",
    "    # 1. Initialize features.\n",
    "    x = jnp.concatenate((masses[..., None], positions), axis=-1) # Shape (..., N, 4).\n",
    "    x = x[..., None, :, None]  # Shape (..., N, 1, 4, 1).\n",
    "\n",
    "    # 2. Apply transformations.\n",
    "    x = e3x.nn.Dense(features=self.features)(x)  # Shape (..., N, 1, 4, features).\n",
    "    x = e3x.nn.TensorDense(max_degree=self.max_degree)(x)  # Shape (..., N, 2, (max_degree+1)**2, features).\n",
    "    x = e3x.nn.TensorDense(  # Shape (..., N, 2, 9, 1).\n",
    "        features=1,\n",
    "        max_degree=2,\n",
    "    )(x)\n",
    "    # Try it: Zero-out irrep of degree 1 to only produce symmetric output tensors.\n",
    "    # x = x.at[..., :, 1:4, :].set(0)\n",
    "\n",
    "    # 3. Collect even irreps from feature channel 0 and sum over contributions from individual points.\n",
    "    x = jnp.sum(x[..., 0, :, 0], axis=-2)  # Shape (..., (max_degree+1)**2).\n",
    "\n",
    "    # 4. Convert output irreps to 3x3 matrix and return.\n",
    "    cg = e3x.so3.clebsch_gordan(max_degree1=1, max_degree2=1, max_degree3=2)  # Shape (4, 4, 9).\n",
    "    y = jnp.einsum('...l,nml->...nm', x, cg[1:, 1:, :])  # Shape (..., 3, 3).\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_loss(prediction, target):\n",
    "  return jnp.mean(optax.l2_loss(prediction, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'optimizer_update'))\n",
    "def train_step(model_apply, optimizer_update, batch, opt_state, params):\n",
    "  def loss_fn(params):\n",
    "    inertia_tensor = model_apply(params, batch['masses'], batch['positions'])\n",
    "    loss = mean_squared_loss(inertia_tensor, batch['inertia_tensor'])\n",
    "    return loss\n",
    "  loss, grad = jax.value_and_grad(loss_fn)(params)\n",
    "  updates, opt_state = optimizer_update(grad, opt_state, params)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "  return params, opt_state, loss\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('model_apply',))\n",
    "def eval_step(model_apply, batch, params):\n",
    "  inertia_tensor = model_apply(params, batch['masses'], batch['positions'])\n",
    "  loss = mean_squared_loss(inertia_tensor, batch['inertia_tensor'])\n",
    "  return loss\n",
    "\n",
    "def train_model(key, model, train_data, valid_data, num_epochs, learning_rate, batch_size):\n",
    "  # Initialize model parameters and optimizer state.\n",
    "  key, init_key = jax.random.split(key)\n",
    "  optimizer = optax.adam(learning_rate)\n",
    "  params = model.init(init_key, train_data['masses'][0:1], train_data['positions'][0:1])\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  # Determine the number of training steps per epoch.\n",
    "  train_size = len(train_data['masses'])\n",
    "  steps_per_epoch = train_size//batch_size\n",
    "\n",
    "  # Train for 'num_epochs' epochs.\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    # Draw random permutations for fetching batches from the train data.\n",
    "    key, shuffle_key = jax.random.split(key)\n",
    "    perms = jax.random.permutation(shuffle_key, train_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # Skip the last batch (if incomplete).\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    # Loop over all batches.\n",
    "    train_loss = 0.0  # For keeping a running average of the loss.\n",
    "    for i, perm in enumerate(perms):\n",
    "      batch = {k: v[perm, ...] for k, v in train_data.items()}\n",
    "      params, opt_state, loss = train_step(\n",
    "          model_apply=model.apply,\n",
    "          optimizer_update=optimizer.update,\n",
    "          batch=batch,\n",
    "          opt_state=opt_state,\n",
    "          params=params\n",
    "      )\n",
    "      train_loss += (loss - train_loss)/(i+1)\n",
    "\n",
    "    # Evaluate on the test set after each training epoch.\n",
    "    valid_loss = eval_step(\n",
    "        model_apply=model.apply,\n",
    "        batch=valid_data,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    # Print progress.\n",
    "    print(f\"epoch {epoch : 4d} train loss {train_loss : 8.6f} valid loss {valid_loss : 8.6f}\")\n",
    "\n",
    "  # Return final model parameters.\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PRNGKey for random number generation.\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Generate train and test datasets.\n",
    "key, data_key = jax.random.split(key)\n",
    "train_data, valid_data = generate_datasets(data_key)\n",
    "\n",
    "# Define training hyperparameters.\n",
    "learning_rate = 0.002\n",
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(train_data['masses'][0:1].shape)\\nprint(train_data['positions'][0:1].shape)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(train_data['masses'][0:1].shape)\n",
    "print(train_data['positions'][0:1].shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'key, train_key = jax.random.split(key)\\nmodel = Model()\\nparams = train_model(\\n  key=train_key,\\n  model=model,\\n  train_data=train_data,\\n  valid_data=valid_data,\\n  num_epochs=num_epochs,\\n  learning_rate=learning_rate,\\n  batch_size=batch_size,\\n)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''key, train_key = jax.random.split(key)\n",
    "model = Model()\n",
    "params = train_model(\n",
    "  key=train_key,\n",
    "  model=model,\n",
    "  train_data=train_data,\n",
    "  valid_data=valid_data,\n",
    "  num_epochs=num_epochs,\n",
    "  learning_rate=learning_rate,\n",
    "  batch_size=batch_size,\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i = 0\\nmasses, positions, target = valid_data['masses'][i], valid_data['positions'][i], valid_data['inertia_tensor'][i]\\nprediction = model.apply(params, masses, positions)\\n\\nprint('target')\\nprint(target)\\nprint('prediction')\\nprint(prediction)\\nprint('mean squared error', jnp.mean((prediction-target)**2))\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''i = 0\n",
    "masses, positions, target = valid_data['masses'][i], valid_data['positions'][i], valid_data['inertia_tensor'][i]\n",
    "prediction = model.apply(params, masses, positions)\n",
    "\n",
    "print('target')\n",
    "print(target)\n",
    "print('prediction')\n",
    "print(prediction)\n",
    "print('mean squared error', jnp.mean((prediction-target)**2))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "R\n",
      "R_units\n",
      "z\n",
      "E\n",
      "E_units\n",
      "F\n",
      "F_units\n",
      "D\n",
      "D_units\n",
      "Q\n",
      "name\n",
      "README\n",
      "theory\n",
      "Dipole moment shape array (5042, 3)\n",
      "Dipole moment units eAng\n",
      "Atomic numbers [23 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "filename = \"test_data.npz\"\n",
    "dataset= np.load(filename)\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "print('Dipole moment shape array',dataset['D'].shape)\n",
    "print('Dipole moment units', dataset['D_units'])\n",
    "\n",
    "print('Atomic numbers', dataset['z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dipole Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(filename, key, num_train, num_valid):\n",
    "    # Load the dataset.\n",
    "    dataset = np.load(filename)\n",
    "    num_data = len(dataset[\"E\"])\n",
    "    Z=jnp.full(16,14)\n",
    "    Z=jnp.append(Z,23)\n",
    "    Z=jnp.expand_dims(Z,axis=0)\n",
    "    Z=jnp.repeat(Z, num_data, axis=0)\n",
    "    num_draw = num_train + num_valid\n",
    "    if num_draw > num_data:\n",
    "        raise RuntimeError(\n",
    "            f\"datasets only contains {num_data} points, requested num_train={num_train}, num_valid={num_valid}\"\n",
    "        )\n",
    "\n",
    "    # Randomly draw train and validation sets from dataset.\n",
    "    choice = np.asarray(\n",
    "        jax.random.choice(key, num_data, shape=(num_draw,), replace=False)\n",
    "    )\n",
    "    train_choice = choice[:num_train]\n",
    "    valid_choice = choice[num_train:]\n",
    "\n",
    "    # Collect and return train and validation sets.\n",
    "    train_data = dict(\n",
    "        #energy=jnp.asarray(dataset[\"E\"][train_choice, 0] - mean_energy),\n",
    "        #forces=jnp.asarray(dataset[\"F\"][train_choice]),\n",
    "        dipole_moment= jnp.asarray(dataset[\"D\"][train_choice]),\n",
    "        atomic_numbers=jnp.asarray(Z[train_choice]),\n",
    "        # atomic_numbers=jnp.asarray(z_hack),\n",
    "        positions=jnp.asarray(dataset[\"R\"][train_choice]),\n",
    "    )\n",
    "    valid_data = dict(\n",
    "        #energy=jnp.asarray(dataset[\"E\"][valid_choice, 0] - mean_energy),\n",
    "        #forces=jnp.asarray(dataset[\"F\"][valid_choice]),\n",
    "        atomic_numbers=jnp.asarray(Z[valid_choice]),\n",
    "        dipole_moment= jnp.asarray(dataset[\"D\"][valid_choice]),\n",
    "        # atomic_numbers=jnp.asarray(z_hack),\n",
    "        positions=jnp.asarray(dataset[\"R\"][valid_choice]),\n",
    "    )\n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "num_train=3000\n",
    "num_val=2000\n",
    "train_data,valid_data=prepare_datasets(filename,key, num_train,num_val)\n",
    "print(train_data['dipole_moment'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dipole_Moment(nn.Module):\n",
    "    # features = 1\n",
    "    # max_degree = 1\n",
    "    @nn.compact\n",
    "    def __call__(self,atomic_numbers, positions):  # Shapes (..., N) and (..., N, 3).\n",
    "        # 1. Initialize features\n",
    "        '''dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(17)\n",
    "        print('dst_idx',dst_idx.shape)\n",
    "        dst_idx = jnp.expand_dims(dst_idx, axis=0)  \n",
    "        src_idx = jnp.expand_dims(src_idx, axis=0)  \n",
    "        dst_idx = jnp.repeat(dst_idx, positions.shape[0], axis=0)\n",
    "        src_idx = jnp.repeat(src_idx, positions.shape[0], axis=0)\n",
    "        print('dst_idx after expansion',dst_idx.shape)\n",
    "        positions_dst = e3x.ops.gather_dst(positions, dst_idx=dst_idx)\n",
    "        positions_src = e3x.ops.gather_src(positions, src_idx=src_idx)\n",
    "        displacements = positions_src - positions_dst\n",
    "        print('positions',positions.shape)\n",
    "        print('displacements',displacements.shape)\n",
    "        #x = e3x.nn.Embed(num_embeddings=self.max_atomic_number + 1, features=self.features)(atomic_numbers)\n",
    "        Z= e3x.nn.Embed(num_embeddings=23, features=272)(atomic_numbers)\n",
    "        print('atomic_numbers',atomic_numbers.shape)\n",
    "        print('Z',Z.shape)\n",
    "        Z=Z[0,...]\n",
    "        Z=jnp.reshape(Z, (272, 17, 1))\n",
    "        print('Z',Z.shape)\n",
    "        x = jnp.concatenate((Z, displacements), axis=-1) '''\n",
    "        positions -= positions[0, ...]\n",
    "        print('aaaaaa')\n",
    "        x = jnp.concatenate(\n",
    "            (atomic_numbers[..., None], positions), axis=-1\n",
    "        )  # Shape (..., N, 4).\n",
    "        # print(\"Initial shape:\", x.shape)\n",
    "        x = x[..., None, :, None]  # Shape (..., N, 1, 3, 1).\n",
    "        \n",
    "        # print(\"x shape:\", x.shape)\n",
    "        # 2. Apply transformations.\n",
    "        # First Dense block with residual connection\n",
    "        #residual = e3x.nn.Dense(features=256)(x)\n",
    "        #x = nn.relu(residual)\n",
    "        x = e3x.nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        #x = x + residual  # Add residual connection\n",
    "\n",
    "        # Layer Normalization\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Second Dense block\n",
    "        #residual = e3x.nn.Dense(features=128)(x)\n",
    "        #x = nn.relu(residual)\n",
    "        x = e3x.nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        #x = x + residual  # Add residual connection\n",
    "\n",
    "        # Layer Normalization\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Adding more complexity with TensorDense and additional layers\n",
    "        x = e3x.nn.TensorDense(features=64, max_degree=2)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = e3x.nn.TensorDense(features=32, max_degree=2)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        x = e3x.nn.TensorDense(features=1, max_degree=1)(x)\n",
    "        # print(\"After TensorDense layer:\", x.shape)\n",
    "        # x = e3x.nn.Dense(features=16)(x)\n",
    "        # x = e3x.nn.Dense(features=1)(x)\n",
    "        x = jnp.sum(x, axis=-4)\n",
    "        # print(\"After sum:\", x.shape)\n",
    "        # x=jnp.sum(x, axis=0)\n",
    "        # print(\"After second sum:\", x.shape)\n",
    "        y = x[..., 1, 1:4, 0]\n",
    "        # y = x[1, 1:4, 0]\n",
    "        # y=y[None,...]\n",
    "        # print(\"After slicing:\", y.shape)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dm_model = Dipole_Moment()\\nkey = jax.random.PRNGKey(0)\\n\\n# Generate train and test datasets.\\nkey, data_key = jax.random.split(key)\\ntrain_data, valid_data = generate_datasets(data_key)\\nparams = dm_model.init(key, train_data['atomic_numbers'][0:1], train_data['positions'][0:1])\\nmoment=dm_model.apply(params,train_data['atomic_numbers'][0:1], train_data['positions'][0:1])\\nprint(moment.shape)\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dm_model = Dipole_Moment()\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Generate train and test datasets.\n",
    "key, data_key = jax.random.split(key)\n",
    "train_data, valid_data = generate_datasets(data_key)\n",
    "params = dm_model.init(key, train_data['atomic_numbers'][0:1], train_data['positions'][0:1])\n",
    "moment=dm_model.apply(params,train_data['atomic_numbers'][0:1], train_data['positions'][0:1])\n",
    "print(moment.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'optimizer_update'))\n",
    "def train_step(model_apply, optimizer_update, batch, opt_state, params):\n",
    "\n",
    "    def loss_fn(params):\n",
    "        print(batch[\"positions\"].shape)\n",
    "        dipole_moment = model_apply(params, batch[\"atomic_numbers\"], batch[\"positions\"])\n",
    "        loss = mean_squared_loss(dipole_moment, batch[\"dipole_moment\"])\n",
    "        return loss\n",
    "\n",
    "    loss, grad = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer_update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('model_apply',))\n",
    "def eval_step(model_apply, batch, params):\n",
    "  dipole_moment = model_apply(params,batch['atomic_numbers'],batch['positions'])\n",
    "  loss = mean_squared_loss(dipole_moment, batch['dipole_moment'])\n",
    "  return loss\n",
    "\n",
    "def train_model(key, model, train_data, valid_data, num_epochs, learning_rate, batch_size):\n",
    "  # Initialize model parameters and optimizer state.\n",
    "  key, init_key = jax.random.split(key)\n",
    "  optimizer = optax.adam(learning_rate)\n",
    "  params = model.init(init_key,train_data['atomic_numbers'][0:1],train_data['positions'][0:1])\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  # Determine the number of training steps per epoch.\n",
    "  train_size = len(train_data['positions'])\n",
    "  steps_per_epoch = train_size//batch_size\n",
    "\n",
    "  # Train for 'num_epochs' epochs.\n",
    "  list_train_loss = []\n",
    "  list_val_loss = []\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    # Draw random permutations for fetching batches from the train data.\n",
    "    key, shuffle_key = jax.random.split(key)\n",
    "    perms = jax.random.permutation(shuffle_key, train_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # Skip the last batch (if incomplete).\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    #print(perms)\n",
    "    # Loop over all batches.\n",
    "    train_loss = 0.0  # For keeping a running average of the loss.\n",
    "\n",
    "    for i, perm in enumerate(perms):\n",
    "      batch = {k: v[perm, ...] for k, v in train_data.items()}\n",
    "      \n",
    "      params, opt_state, loss = train_step(\n",
    "          model_apply=model.apply,\n",
    "          optimizer_update=optimizer.update,\n",
    "          batch=batch,\n",
    "          opt_state=opt_state,\n",
    "          params=params\n",
    "      )\n",
    "      train_loss += (loss - train_loss)/(i+1)\n",
    "      \n",
    "    # Evaluate on the test set after each training epoch.\n",
    "    valid_loss = eval_step(\n",
    "        model_apply=model.apply,\n",
    "        batch=valid_data,\n",
    "        params=params\n",
    "    )\n",
    "    list_val_loss.append(valid_loss)\n",
    "    list_train_loss.append(train_loss)\n",
    "    # Print progress.\n",
    "    print(f\"epoch {epoch : 4d} train loss {train_loss : 8.6f} valid loss {valid_loss : 8.6f}\")\n",
    "\n",
    "  # Return final model parameters.\n",
    "  return params ,list_train_loss , list_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17)\n",
      "(1, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data['atomic_numbers'][0:1].shape)\n",
    "print(train_data['positions'][0:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PRNGKey for random number generation.\n",
    "key = jax.random.PRNGKey(0)\n",
    "num_train=3000\n",
    "num_val=2000\n",
    "train_data, valid_data = prepare_datasets(filename,key, num_train,num_val)\n",
    "\n",
    "# Define training hyperparameters.\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(train_data['positions'][0:1].shape)\\nprint(train_data['atomic_numbers'][0:1].shape)\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(train_data['positions'][0:1].shape)\n",
    "print(train_data['atomic_numbers'][0:1].shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "(512, 17, 3)\n",
      "aaaaaa\n",
      "aaaaaa\n",
      "epoch    1 train loss  3.617877 valid loss  0.545769\n",
      "epoch    2 train loss  0.452163 valid loss  0.474390\n",
      "epoch    3 train loss  0.295970 valid loss  0.283510\n",
      "epoch    4 train loss  0.189194 valid loss  0.034753\n",
      "epoch    5 train loss  0.078586 valid loss  0.027656\n",
      "epoch    6 train loss  0.051103 valid loss  0.036802\n",
      "epoch    7 train loss  0.042537 valid loss  0.023525\n",
      "epoch    8 train loss  0.032300 valid loss  0.031075\n",
      "epoch    9 train loss  0.027853 valid loss  0.018487\n",
      "epoch   10 train loss  0.018331 valid loss  0.014081\n"
     ]
    }
   ],
   "source": [
    "key, train_key = jax.random.split(key)\n",
    "model = Dipole_Moment()\n",
    "params, list_train_loss, list_val_loss = train_model(\n",
    "    key=train_key,\n",
    "    model=model,\n",
    "    train_data=train_data,\n",
    "    valid_data=valid_data,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from typing import List\n",
    "\n",
    "def create_loss_plot(\n",
    "    train_loss: List[np.ndarray],\n",
    "    val_loss: List[np.ndarray],\n",
    "    train_label: str,\n",
    "    val_label: str,\n",
    "    title: str,\n",
    "    filename: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a Plotly figure with training and validation loss curves and save it as an HTML file.\n",
    "\n",
    "    Args:\n",
    "        train_loss (List[np.ndarray]): List of training loss values.\n",
    "        val_loss (List[np.ndarray]): List of validation loss values.\n",
    "        train_label (str): Label for the training loss curve.\n",
    "        val_label (str): Label for the validation loss curve.\n",
    "        title (str): Title of the plot.\n",
    "        filename (str): Filename to save the HTML file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    train_loss_list = [float(loss) for loss in train_loss]\n",
    "    val_loss_list = [float(loss) for loss in val_loss]\n",
    "\n",
    "    trace_train = go.Scatter(y=train_loss_list, mode=\"lines\", name=train_label)\n",
    "    trace_val = go.Scatter(y=val_loss_list, mode=\"lines\", name=val_label)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(trace_train)\n",
    "    fig.add_trace(trace_val)\n",
    "    fig.update_layout(\n",
    "        title=title, xaxis_title=\"Epoch\", yaxis_title=\"Loss\", legend_title=\"Legend\"\n",
    "    )\n",
    "    pio.write_html(fig, filename)\n",
    "    #fig.show()\n",
    "\n",
    "create_loss_plot(\n",
    "    list_train_loss,\n",
    "    list_val_loss,\n",
    "    \"Training Loss\",\n",
    "    \"Validation Loss\",\n",
    "    \"Training vs Validation Loss (Train)\",\n",
    "    \"train_vs_val_train_dipole_moment.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "target\n",
      "[ 1.5010834  -0.35230795  1.6916788 ]\n",
      "prediction\n",
      "[ 1.2756575  -0.20945098  1.632235  ]\n",
      "mean squared error 0.024919493\n",
      "positions \n",
      " [[ 1.3739698  -0.36267418  1.7607656 ]\n",
      " [ 1.0720738   0.6241141  -0.73667634]\n",
      " [-0.72627133 -1.6513554   2.6751056 ]\n",
      " [ 0.36511922 -0.6054491   4.4396477 ]\n",
      " [-1.0101337  -0.31764832  0.65454173]\n",
      " [ 2.8003755  -0.15685865  4.326635  ]\n",
      " [ 1.8958619  -2.5351772   3.4812946 ]\n",
      " [ 0.08705649  2.1099863   1.0994254 ]\n",
      " [ 0.6552997  -3.044066    1.1402597 ]\n",
      " [ 0.6292777  -1.7157842  -0.89606315]\n",
      " [-0.9160637   0.91140497  2.9305716 ]\n",
      " [ 1.3739641   1.775827    3.3651717 ]\n",
      " [ 2.5825186   2.0538971   0.9288267 ]\n",
      " [ 2.7610474  -2.0349882   0.22516835]\n",
      " [ 3.5957031  -1.5967042   2.3485258 ]\n",
      " [ 3.7129374   0.07741954  0.03268949]\n",
      " [ 3.9070163   0.6479711   2.2983937 ]]\n"
     ]
    }
   ],
   "source": [
    "i = 45\n",
    "Z, positions, target = valid_data['atomic_numbers'][i], valid_data['positions'][i], valid_data['dipole_moment'][i]\n",
    "prediction = model.apply(params, Z, positions)\n",
    "\n",
    "print('target')\n",
    "print(target)\n",
    "print('prediction')\n",
    "print(prediction)\n",
    "print('mean squared error', jnp.mean((prediction-target)**2))\n",
    "print('positions \\n', positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "target\n",
      "[ 1.5010834  -0.35230795  1.6916788 ]\n",
      "prediction\n",
      "[ 1.2756575  -0.20945098  1.632235  ]\n",
      "mean squared error 0.024919493\n",
      "positions \n",
      " [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-3.0189598e-01  9.8678827e-01 -2.4974418e+00]\n",
      " [-2.1002412e+00 -1.2886813e+00  9.1434002e-01]\n",
      " [-1.0088506e+00 -2.4277490e-01  2.6788821e+00]\n",
      " [-2.3841035e+00  4.5025855e-02 -1.1062238e+00]\n",
      " [ 1.4264057e+00  2.0581552e-01  2.5658693e+00]\n",
      " [ 5.2189207e-01 -2.1725030e+00  1.7205291e+00]\n",
      " [-1.2869133e+00  2.4726605e+00 -6.6134012e-01]\n",
      " [-7.1867007e-01 -2.6813917e+00 -6.2050581e-01]\n",
      " [-7.4469209e-01 -1.3531101e+00 -2.6568286e+00]\n",
      " [-2.2900336e+00  1.2740791e+00  1.1698060e+00]\n",
      " [-5.7220459e-06  2.1385012e+00  1.6044061e+00]\n",
      " [ 1.2085488e+00  2.4165714e+00 -8.3193886e-01]\n",
      " [ 1.3870776e+00 -1.6723139e+00 -1.5355972e+00]\n",
      " [ 2.2217333e+00 -1.2340300e+00  5.8776021e-01]\n",
      " [ 2.3389676e+00  4.4009373e-01 -1.7280761e+00]\n",
      " [ 2.5330465e+00  1.0106453e+00  5.3762817e-01]]\n"
     ]
    }
   ],
   "source": [
    "i = 45\n",
    "Z, positions, target = valid_data['atomic_numbers'][i], valid_data['positions'][i], valid_data['dipole_moment'][i]\n",
    "positions -= positions[0, ...]\n",
    "prediction = model.apply(params, Z, positions)\n",
    "\n",
    "print('target')\n",
    "print(target)\n",
    "print('prediction')\n",
    "print(prediction)\n",
    "print('mean squared error', jnp.mean((prediction-target)**2))\n",
    "print('positions \\n', positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1.3739698 , -0.36267418,  1.7607656 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "target\n",
      "[ 1.5010834  -0.35230795  1.6916788 ]\n",
      "prediction\n",
      "[ 1.2794365  -0.21050556  1.640639  ]\n",
      "mean squared error 0.023946777\n",
      "positions \n",
      " [[100.       100.       100.      ]\n",
      " [ 99.698105 100.986786  97.502556]\n",
      " [ 97.89976   98.71132  100.91434 ]\n",
      " [ 98.99115   99.757225 102.67888 ]\n",
      " [ 97.6159   100.04503   98.893776]\n",
      " [101.42641  100.20582  102.56587 ]\n",
      " [100.52189   97.8275   101.72053 ]\n",
      " [ 98.71309  102.472664  99.33866 ]\n",
      " [ 99.28133   97.31861   99.37949 ]\n",
      " [ 99.25531   98.64689   97.34317 ]\n",
      " [ 97.70997  101.27408  101.16981 ]\n",
      " [ 99.99999  102.138504 101.60441 ]\n",
      " [101.20855  102.41657   99.16806 ]\n",
      " [101.38708   98.32768   98.4644  ]\n",
      " [102.22173   98.76597  100.58776 ]\n",
      " [102.33897  100.440094  98.27193 ]\n",
      " [102.53304  101.01064  100.53763 ]]\n"
     ]
    }
   ],
   "source": [
    "i = 45\n",
    "Z, positions, target = valid_data['atomic_numbers'][i], valid_data['positions'][i], valid_data['dipole_moment'][i]\n",
    "positions-=positions[0,...]\n",
    "positions+=jnp.array([100,100,100])\n",
    "prediction = model.apply(params, Z, positions)\n",
    "\n",
    "print('target')\n",
    "print(target)\n",
    "print('prediction')\n",
    "print(prediction)\n",
    "print('mean squared error', jnp.mean((prediction-target)**2))\n",
    "print('positions \\n', positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP Dipole Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MP_Dipole_Moment(nn.Module):\n",
    "    features: int = 32\n",
    "    max_degree: int = 2\n",
    "    num_iterations: int = 3\n",
    "    num_basis_functions: int = 8\n",
    "    cutoff: float = 5.0\n",
    "    max_atomic_number: int = 118  # This is overkill for most applications.\n",
    "\n",
    "    def dipole_moment(\n",
    "        self, atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size\n",
    "    ):\n",
    "        # 1. Calculate displacement vectors.\n",
    "        positions_dst = e3x.ops.gather_dst(positions, dst_idx=dst_idx)\n",
    "        positions_src = e3x.ops.gather_src(positions, src_idx=src_idx)\n",
    "        displacements = positions_src - positions_dst  # Shape (num_pairs, 3).\n",
    "\n",
    "        # 2. Expand displacement vectors in basis functions.\n",
    "        basis = e3x.nn.basis(  # Shape (num_pairs, 1, (max_degree+1)**2, num_basis_functions).\n",
    "            displacements,\n",
    "            num=self.num_basis_functions,\n",
    "            max_degree=self.max_degree,\n",
    "            radial_fn=e3x.nn.reciprocal_bernstein,\n",
    "            cutoff_fn=functools.partial(e3x.nn.smooth_cutoff, cutoff=self.cutoff),\n",
    "        )\n",
    "\n",
    "        # 3. Embed atomic numbers in feature space, x has shape (num_atoms, 1, 1, features).\n",
    "        x = e3x.nn.Embed(\n",
    "            num_embeddings=self.max_atomic_number + 1, features=self.features\n",
    "        )(atomic_numbers)\n",
    "        #print('Embed',x.shape)\n",
    "        #print('Basis',basis.shape)\n",
    "\n",
    "        # 4. Perform iterations (message-passing + atom-wise refinement).\n",
    "        for i in range(self.num_iterations):\n",
    "            # Message-pass.\n",
    "            if i == self.num_iterations - 1:  # Final iteration.\n",
    "                # Since we will only use scalar features after the final message-pass, we do not want to produce non-scalar\n",
    "                # features for efficiency reasons.\n",
    "                y = e3x.nn.MessagePass(max_degree=2, include_pseudotensors=False)(\n",
    "                    x, basis, dst_idx=dst_idx, src_idx=src_idx\n",
    "                )\n",
    "                #print('Final',y.shape)\n",
    "                # After the final message pass, we can safely throw away all non-scalar features.\n",
    "                x = e3x.nn.change_max_degree_or_type(\n",
    "                    x, max_degree=2, include_pseudotensors=False\n",
    "                )\n",
    "            else:\n",
    "                # In intermediate iterations, the message-pass should consider all possible coupling paths.\n",
    "                y = e3x.nn.MessagePass()(x, basis, dst_idx=dst_idx, src_idx=src_idx)\n",
    "                #print('Message',y.shape)\n",
    "            y = e3x.nn.add(x, y)\n",
    "\n",
    "            # Atom-wise refinement MLP.\n",
    "            y = e3x.nn.Dense(self.features)(y)\n",
    "            y = e3x.nn.silu(y)\n",
    "            y = e3x.nn.Dense(self.features, kernel_init=jax.nn.initializers.zeros)(y)\n",
    "\n",
    "            # Residual connection.\n",
    "            x = e3x.nn.add(x, y)\n",
    "            #print('Residual',x.shape)\n",
    "\n",
    "        # 5. Predict atomic energies with an ordinary dense layer.\n",
    "        #element_bias = self.param(\n",
    "        #    \"element_bias\",\n",
    "        #    lambda rng, shape: jnp.zeros(shape),\n",
    "        #    (self.max_atomic_number + 1),\n",
    "        #)\n",
    "        x = nn.Dense(1, use_bias=False, kernel_init=jax.nn.initializers.zeros)(x)  # (..., Natoms, 1, 9, 1)\n",
    "        #print('After dense:',x.shape)\n",
    "        x=jnp.sum(x, axis=-4) \n",
    "        #print(\"After sum:\", x.shape)\n",
    "        x = x[..., 1:4, 0]\n",
    "        #print('After slicing:' ,x.shape)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        atomic_numbers,\n",
    "        positions,\n",
    "        dst_idx,\n",
    "        src_idx,\n",
    "        batch_segments=None,\n",
    "        batch_size=None,\n",
    "    ):\n",
    "        if batch_segments is None:\n",
    "            batch_segments = jnp.zeros_like(atomic_numbers)\n",
    "            batch_size = 1\n",
    "\n",
    "        # Since we want to also predict forces, i.e. the gradient of the energy w.r.t. positions (argument 1), we use\n",
    "        # jax.value_and_grad to create a function for predicting both energy and forces for us.\n",
    "        \n",
    "        dipole = self.dipole_moment(atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size)\n",
    "\n",
    "        return dipole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed (17, 1, 1, 32)\n",
      "Basis (272, 1, 9, 8)\n",
      "Message (17, 1, 9, 32)\n",
      "Residual (17, 1, 9, 32)\n",
      "Message (17, 2, 9, 32)\n",
      "Residual (17, 2, 9, 32)\n",
      "Message (17, 2, 9, 32)\n",
      "Residual (17, 2, 9, 32)\n",
      "Final (17, 1, 9, 32)\n",
      "Residual (17, 1, 9, 32)\n",
      "After dense: (17, 1, 9, 1)\n",
      "After sum: (1, 9, 1)\n",
      "After slicing: (1, 3)\n",
      "Embed (17, 1, 1, 32)\n",
      "Basis (272, 1, 9, 8)\n",
      "Message (17, 1, 9, 32)\n",
      "Residual (17, 1, 9, 32)\n",
      "Message (17, 2, 9, 32)\n",
      "Residual (17, 2, 9, 32)\n",
      "Message (17, 2, 9, 32)\n",
      "Residual (17, 2, 9, 32)\n",
      "Final (17, 1, 9, 32)\n",
      "Residual (17, 1, 9, 32)\n",
      "After dense: (17, 1, 9, 1)\n",
      "After sum: (1, 9, 1)\n",
      "After slicing: (1, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "dm_model = MP_Dipole_Moment()\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "# Generate train and test datasets.\n",
    "key, data_key = jax.random.split(key)\n",
    "num_train=10\n",
    "num_val=2\n",
    "train_data,valid_data=prepare_datasets(filename,key, num_train,num_val)\n",
    "dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(17)\n",
    "params = dm_model.init(key,\n",
    "    atomic_numbers=train_data['atomic_numbers'][0],\n",
    "    positions=train_data['positions'][0],\n",
    "    dst_idx=dst_idx,\n",
    "    src_idx=src_idx,\n",
    "  )\n",
    "moment = dm_model.apply(\n",
    "            params,\n",
    "            atomic_numbers=train_data[\"atomic_numbers\"][0],\n",
    "            positions=train_data[\"positions\"][0],\n",
    "            dst_idx=dst_idx,\n",
    "            src_idx=src_idx,\n",
    "            batch_segments=None,\n",
    "            batch_size=1,\n",
    "        )\n",
    "print(moment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batches(key, data, batch_size):\n",
    "    # Determine the number of training steps per epoch.\n",
    "    data_size = len(data[\"dipole_moment\"])\n",
    "    steps_per_epoch = data_size // batch_size\n",
    "\n",
    "    # Draw random permutations for fetching batches from the train data.\n",
    "    perms = jax.random.permutation(key, data_size)\n",
    "    perms = perms[\n",
    "        : steps_per_epoch * batch_size\n",
    "    ]  # Skip the last batch (if incomplete).\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    # Prepare entries that are identical for each batch.\n",
    "    num_atoms = len(data[\"atomic_numbers\"])\n",
    "    batch_segments = jnp.repeat(jnp.arange(batch_size), num_atoms)\n",
    "    atomic_numbers = jnp.tile(data[\"atomic_numbers\"], batch_size)\n",
    "    offsets = jnp.arange(batch_size) * num_atoms\n",
    "    dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(num_atoms)\n",
    "    dst_idx = (dst_idx + offsets[:, None]).reshape(-1)\n",
    "    src_idx = (src_idx + offsets[:, None]).reshape(-1)\n",
    "\n",
    "    # Assemble and return batches.\n",
    "    return [\n",
    "        dict(\n",
    "            dipole_moment=data[\"dipole_moment\"][perm].reshape(-1, 3),\n",
    "            atomic_numbers=atomic_numbers,\n",
    "            positions=data[\"positions\"][perm].reshape(-1, 3),\n",
    "            dst_idx=dst_idx,\n",
    "            src_idx=src_idx,\n",
    "            batch_segments=batch_segments,\n",
    "        )\n",
    "        for perm in perms\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'optimizer_update', 'batch_size'))\n",
    "def train_step(model_apply, optimizer_update, batch, batch_size, opt_state, params):\n",
    "  def loss_fn(params):\n",
    "    dipole = model_apply(\n",
    "      params,\n",
    "      atomic_numbers=batch['atomic_numbers'],\n",
    "      positions=batch['positions'],\n",
    "      dst_idx=batch['dst_idx'],\n",
    "      src_idx=batch['src_idx'],\n",
    "      batch_segments=batch['batch_segments'],\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "    loss = mean_squared_loss(\n",
    "      dipole_prediction=dipole,\n",
    "      dipole_target=batch['dipole_moment']\n",
    "    )\n",
    "    return loss\n",
    "  loss, grad = jax.value_and_grad(loss_fn)(params)\n",
    "  updates, opt_state = optimizer_update(grad, opt_state, params)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "  return params, opt_state, loss\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=('model_apply', 'batch_size'))\n",
    "def eval_step(model_apply, batch, batch_size, params):\n",
    "  dipole = model_apply(\n",
    "    params,\n",
    "    atomic_numbers=batch['atomic_numbers'],\n",
    "    positions=batch['positions'],\n",
    "    dst_idx=batch['dst_idx'],\n",
    "    src_idx=batch['src_idx'],\n",
    "    batch_segments=batch['batch_segments'],\n",
    "    batch_size=batch_size\n",
    "  )\n",
    "  loss = mean_squared_loss(\n",
    "    energy_prediction=dipole,\n",
    "    energy_target=batch['dipole_moment']\n",
    "  )\n",
    "  return loss\n",
    "\n",
    "\n",
    "def train_model(key, model, train_data, valid_data, num_epochs, learning_rate, batch_size):\n",
    "  # Initialize model parameters and optimizer state.\n",
    "  key, init_key = jax.random.split(key)\n",
    "  optimizer = optax.adam(learning_rate)\n",
    "  dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(len(train_data['atomic_numbers']))\n",
    "  params = model.init(init_key,\n",
    "    atomic_numbers=train_data['atomic_numbers'],\n",
    "    positions=train_data['positions'][0],\n",
    "    dst_idx=dst_idx,\n",
    "    src_idx=src_idx,\n",
    "  )\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  # Batches for the validation set need to be prepared only once.\n",
    "  key, shuffle_key = jax.random.split(key)\n",
    "  valid_batches = prepare_batches(shuffle_key, valid_data, batch_size)\n",
    "\n",
    "  # Train for 'num_epochs' epochs.\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    # Prepare batches.\n",
    "    key, shuffle_key = jax.random.split(key)\n",
    "    train_batches = prepare_batches(shuffle_key, train_data, batch_size)\n",
    "\n",
    "    # Loop over train batches.\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(train_batches):\n",
    "      params, opt_state, loss= train_step(\n",
    "        model_apply=model.apply,\n",
    "        optimizer_update=optimizer.update,\n",
    "        batch=batch,\n",
    "        batch_size=batch_size,\n",
    "        opt_state=opt_state,\n",
    "        params=params\n",
    "      )\n",
    "      train_loss += (loss - train_loss)/(i+1)\n",
    "\n",
    "    # Evaluate on validation set.\n",
    "    valid_loss = 0.0\n",
    "    for i, batch in enumerate(valid_batches):\n",
    "      loss = eval_step(\n",
    "        model_apply=model.apply,\n",
    "        batch=batch,\n",
    "        batch_size=batch_size,\n",
    "        params=params\n",
    "      )\n",
    "      valid_loss += (loss - valid_loss)/(i+1)\n",
    "\n",
    "    # Print progress.\n",
    "    print(f\"epoch: {epoch: 3d}                    train:   valid:\")\n",
    "    print(f\"    loss [a.u.]             {train_loss : 8.3f} {valid_loss : 8.3f}\")\n",
    "\n",
    "\n",
    "  # Return final model parameters.\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
