{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import e3x\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "# Disable future warnings.\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moment_of_inertia_tensor(masses, positions):\n",
    "    diag = jnp.sum(positions**2, axis=-1)[..., None, None] * jnp.eye(3)\n",
    "    outer = positions[..., None, :] * positions[..., :, None]\n",
    "    return jnp.sum(masses[..., None, None] * (diag - outer), axis=-3)\n",
    "\n",
    "\n",
    "def generate_datasets(\n",
    "    key,\n",
    "    num_train=1000,\n",
    "    num_valid=100,\n",
    "    num_points=10,\n",
    "    min_mass=0.0,\n",
    "    max_mass=1.0,\n",
    "    stdev=1.0,\n",
    "):\n",
    "    # Generate random keys.\n",
    "    train_position_key, train_masses_key, valid_position_key, valid_masses_key = (\n",
    "        jax.random.split(key, num=4)\n",
    "    )\n",
    "\n",
    "    # Draw random point masses with random positions.\n",
    "    train_positions = stdev * jax.random.normal(\n",
    "        train_position_key, shape=(num_train, num_points, 3)\n",
    "    )\n",
    "    train_masses = jax.random.uniform(\n",
    "        train_masses_key,\n",
    "        shape=(num_train, num_points),\n",
    "        minval=min_mass,\n",
    "        maxval=max_mass,\n",
    "    )\n",
    "    valid_positions = stdev * jax.random.normal(\n",
    "        valid_position_key, shape=(num_valid, num_points, 3)\n",
    "    )\n",
    "    valid_masses = jax.random.uniform(\n",
    "        valid_masses_key,\n",
    "        shape=(num_valid, num_points),\n",
    "        minval=min_mass,\n",
    "        maxval=max_mass,\n",
    "    )\n",
    "\n",
    "    # Calculate moment of inertia tensors.\n",
    "    train_inertia_tensor = calculate_moment_of_inertia_tensor(\n",
    "        train_masses, train_positions\n",
    "    )\n",
    "    valid_inertia_tensor = calculate_moment_of_inertia_tensor(\n",
    "        valid_masses, valid_positions\n",
    "    )\n",
    "\n",
    "    # Return final train and validation datasets.\n",
    "    train_data = dict(\n",
    "        positions=train_positions,\n",
    "        masses=train_masses,\n",
    "        inertia_tensor=train_inertia_tensor,\n",
    "    )\n",
    "    valid_data = dict(\n",
    "        positions=valid_positions,\n",
    "        masses=valid_masses,\n",
    "        inertia_tensor=valid_inertia_tensor,\n",
    "    )\n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_loss(prediction, target):\n",
    "    return jnp.mean(optax.l2_loss(prediction, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prepare_datasets_test(filename, key, num_train, num_valid, batch_size):\n",
    "    # Load the dataset.\n",
    "    dataset = np.load(filename)\n",
    "    num_data = len(dataset[\"R\"])\n",
    "\n",
    "    Z = jnp.full(1, 23)\n",
    "    Z = jnp.append(Z, jnp.full(16, 14))\n",
    "    Z = jnp.expand_dims(Z, axis=0)\n",
    "    Z = jnp.repeat(Z, num_data, axis=0)\n",
    "    num_draw = num_train + num_valid\n",
    "    if num_draw > num_data:\n",
    "        raise RuntimeError(\n",
    "            f\"datasets only contains {num_data} points, requested num_train={num_train}, num_valid={num_valid}\"\n",
    "        )\n",
    "\n",
    "    # Randomly draw train and validation sets from dataset.\n",
    "    choice = np.asarray(\n",
    "        jax.random.choice(key, num_data, shape=(num_draw,), replace=False)\n",
    "    )\n",
    "    train_choice = choice[:num_train]\n",
    "    valid_choice = choice[num_train:]\n",
    "\n",
    "    # Collect and return train and validation sets.\n",
    "    train_data = dict(\n",
    "        atomic_numbers=jnp.asarray(Z[train_choice]),\n",
    "        positions=jnp.asarray(dataset[\"R\"][train_choice]),\n",
    "    )\n",
    "    valid_data = dict(\n",
    "        atomic_numbers=jnp.asarray(Z[valid_choice]),\n",
    "        positions=jnp.asarray(dataset[\"R\"][valid_choice]),\n",
    "    )\n",
    "\n",
    "    # Split the training data into batches\n",
    "    train_batches = []\n",
    "    for i in range(0, num_train, batch_size):\n",
    "        batch_data = {\n",
    "            \"atomic_numbers\": train_data[\"atomic_numbers\"][i : i + batch_size],\n",
    "            \"positions\": train_data[\"positions\"][i : i + batch_size],\n",
    "        }\n",
    "        train_batches.append(batch_data)\n",
    "\n",
    "    return train_batches, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dipole_Moment(nn.Module):\n",
    "    # features = 1\n",
    "    # max_degree = 1\n",
    "    @nn.compact\n",
    "    def __call__(self, atomic_numbers, positions):  # Shapes (..., N) and (..., N, 3).\n",
    "        # 1. Initialize features\n",
    "        positions -= positions[0, ...]\n",
    "        x = jnp.concatenate(\n",
    "            (atomic_numbers[..., None], positions), axis=-1\n",
    "        )  # Shape (..., N, 4).\n",
    "        x = x[..., None, :, None]  # Shape (..., N, 1, 3, 1).\n",
    "\n",
    "        # Incremento de complejidad con más capas densas\n",
    "        x = e3x.nn.Dense(features=1024)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = e3x.nn.Dense(features=512)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = e3x.nn.Dense(features=256)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Más capas densas\n",
    "        x = e3x.nn.Dense(features=128)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Capas TensorDense adicionales para más complejidad\n",
    "        x = e3x.nn.TensorDense(features=64, max_degree=2)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = e3x.nn.TensorDense(features=32, max_degree=2)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        x = e3x.nn.TensorDense(features=16, max_degree=2)(x)\n",
    "        x = e3x.nn.relu(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "\n",
    "        # Capa final\n",
    "        x = e3x.nn.TensorDense(features=1, max_degree=1)(x)\n",
    "        x = jnp.sum(x, axis=-4)\n",
    "        y = x[..., 1, 1:4, 0]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dipole_Moment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "typ\n",
      "InLine_txt\n",
      "name_original\n",
      "bead\n",
      "number_beads\n",
      "theory_level\n",
      "SuperCell\n",
      "converter_used\n",
      "R (1, 200001, 17, 3)\n",
      "R\n",
      "typ\n",
      "InLine_txt\n",
      "name_original\n",
      "bead\n",
      "number_beads\n",
      "theory_level\n",
      "SuperCell\n",
      "converter_used\n",
      "R (200001, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "###############predict 200 k\n",
    "\n",
    "# huziel\n",
    "filename = \"/home/beemoqc2/Documents/e3x_tranfer/SI16VPLUS_E3X_RETRAINED_WB97X_D_TIGHT_TRP_400K_1B_01_POSITION_0.npz\"\n",
    "dataset = np.load(filename, allow_pickle=True)\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "\n",
    "print(\"R\", dataset[\"R\"].shape)\n",
    "# Modificar el array \"R\"\n",
    "dataset_modified = {\n",
    "    key: np.squeeze(value, axis=0) if key == \"R\" else value\n",
    "    for key, value in dataset.items()\n",
    "}\n",
    "\n",
    "# Guardar el dataset modificado\n",
    "np.savez(\n",
    "    \"/home/beemoqc2/Documents/e3x_tranfer/SI16VPLUS_E3X_RETRAINED_WB97X_D_TIGHT_TRP_400K_1B_01_POSITION_0_reshape.npz\",\n",
    "    **dataset_modified,\n",
    ")\n",
    "\n",
    "filename = \"/home/beemoqc2/Documents/e3x_tranfer/SI16VPLUS_E3X_RETRAINED_WB97X_D_TIGHT_TRP_400K_1B_01_POSITION_0_reshape.npz\"\n",
    "dataset = np.load(filename)\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "\n",
    "print(\"R\", dataset[\"R\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_save_path = (\n",
    "    \"mode_training_Si16Vplus..DFT.SP-GRD.wB97X-D.tight.Data.5042.R_E_F_D_Q.pkl\"\n",
    ")\n",
    "with open(model_save_path, \"rb\") as file:\n",
    "    best_params = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 200000\n",
    "num_val = 1\n",
    "batch_size = 1024  # Ajusta este valor según la capacidad de tu memoria\n",
    "filename = \"/home/beemoqc2/Documents/e3x_tranfer/SI16VPLUS_E3X_RETRAINED_WB97X_D_TIGHT_TRP_400K_1B_01_POSITION_0_reshape.npz\"\n",
    "key = jax.random.PRNGKey(0)\n",
    "train_batches, valid_data = prepare_datasets_test(\n",
    "    filename, key, num_train, num_val, batch_size\n",
    ")\n",
    "\n",
    "i = 0\n",
    "print(len(train_batches))\n",
    "data_final = []\n",
    "for batch in train_batches:\n",
    "    i += 1\n",
    "    print(i)\n",
    "    Z, positions = (\n",
    "        batch[\"atomic_numbers\"],\n",
    "        batch[\"positions\"],\n",
    "    )\n",
    "    positions -= positions[0, ...]\n",
    "    prediction = model.apply(best_params, Z, positions)\n",
    "    data_final.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
